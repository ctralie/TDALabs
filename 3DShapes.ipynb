{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Shape Classification with Sublevelset Filtrations\n",
    "\n",
    "In this module, we will explore how TDA can be used to classify 3D shapes.  We will begine by clustering triangle meshes of humans in different poses by pose.  We will then explore how to cluster a collection of shapes which are undergoing nonrigid transformations.\n",
    "\n",
    "As always, let's first import all of the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import scipy.io as sio\n",
    "from scipy import sparse \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys \n",
    "sys.path.append(\"pyhks\")\n",
    "from HKS import *\n",
    "from DGMTools import *\n",
    "from GeomUtils import *\n",
    "from ripser import ripser, plot_dgms\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's include some code that performs a sublevelset filtration by some scalar function on the vertices of a triangle mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do0DSublevelsetFiltrationMesh(VPos, ITris, fn):\n",
    "    x = fn(VPos, ITris)\n",
    "    N = VPos.shape[0]\n",
    "    # Add edges between adjacent points in the mesh    \n",
    "    I, J = getEdges(VPos, ITris)\n",
    "    V = np.maximum(x[I], x[J])\n",
    "    # Add vertex birth times along the diagonal of the distance matrix\n",
    "    I = np.concatenate((I, np.arange(N)))\n",
    "    J = np.concatenate((J, np.arange(N)))\n",
    "    V = np.concatenate((V, x))\n",
    "    #Create the sparse distance matrix\n",
    "    D = sparse.coo_matrix((V, (I, J)), shape=(N, N)).tocsr()\n",
    "    return ripser(D, distance_matrix=True, maxdim=0)['dgms'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a function which will plot a particular scalar function on XY and XZ slices of the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPCfn(VPos, fn, cmap = 'afmhot'):\n",
    "    \"\"\"\n",
    "    plot an XY slice of a mesh with the scalar function used in a \n",
    "    sublevelset filtration\n",
    "    \"\"\"\n",
    "    x = fn - np.min(fn)\n",
    "    x = x/np.max(x)\n",
    "    c = plt.get_cmap(cmap)\n",
    "    C = c(np.array(np.round(x*255.0), dtype=np.int64))\n",
    "    plt.scatter(VPos[:, 0], VPos[:, 1], 10, c=C)\n",
    "    plt.axis('equal')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.3, 0.3, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Clustering of Human Poses\n",
    "\n",
    "In the first experiment, we will load surfaces of 10 different people, each performing one of 10 different poses, for 100 total.  To classify by pose, we will use the height function as our sublevelset function.  Let's load a few examples to see what they look like.\n",
    "\n",
    "#### Questions\n",
    "* After looking at some examples, why would filtering by height be a good idea for picking up on these poses?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectNum = 1\n",
    "poseNum = 0\n",
    "i = subjectNum*10 + poseNum\n",
    "\n",
    "fn = lambda VPos, ITris: VPos[:, 1] #Return the y coordinate as a function\n",
    "\n",
    "(VPos, _, ITris) = loadOffFile(\"shapes/tr_reg_%.03d.off\"%i)\n",
    "\n",
    "x = fn(VPos, ITris)\n",
    "I = do0DSublevelsetFiltrationMesh(VPos, ITris, fn)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(131)\n",
    "plotPCfn(VPos, x, cmap = 'afmhot')\n",
    "plt.title(\"Subject %i Pose %i\"%(subjectNum, poseNum))\n",
    "plt.subplot(132)\n",
    "plotPCfn(VPos[:, [2, 1, 0]], x, cmap = 'afmhot')\n",
    "plt.subplot(133)\n",
    "plot_dgms([I])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in all of the meshes and sort them so that contiguous groups of 10 meshes are the same pose (by default they are sorted by subject)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = []\n",
    "for poseNum in range(10):\n",
    "    for subjectNum in range(10):\n",
    "        i = subjectNum*10 + poseNum\n",
    "        VPos, _, ITris = loadOffFile(\"shapes/tr_reg_%.03d.off\"%i)\n",
    "        meshes.append((VPos, ITris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the 0D sublevelset filtration on all of the shapes, followed by a Wasserstein distance computation between all pairs to examine how different shapes cluster together.  We also display the result of 3D multidimensional scaling using the matrix of all pairs of Wasserstein distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = []\n",
    "N = len(meshes)\n",
    "print(\"Computing persistence diagrams...\")\n",
    "for i, (VPos, ITris) in enumerate(meshes):\n",
    "    x = fn(VPos, ITris)\n",
    "    I = do0DSublevelsetFiltrationMesh(VPos, ITris, fn)\n",
    "    I = I[np.isfinite(I[:, 1]), :]\n",
    "    dgms.append(I)\n",
    "\n",
    "# Compute Wasserstein distances\n",
    "DWass = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    if i%10 == 0:\n",
    "        print(\"Comparing pose %i...\"%(i/10))\n",
    "    for j in range(i+1, N):\n",
    "        _, DWass[i, j], _ = getWassersteinDist(dgms[i], dgms[j])\n",
    "DWass = DWass + DWass.T\n",
    "\n",
    "# Now do MDS and PCA, respectively\n",
    "mds = MDS(n_components=3, dissimilarity='precomputed')\n",
    "mds.fit_transform(DWass)\n",
    "XWass = mds.embedding_\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(DWass, cmap = 'afmhot', interpolation = 'none')\n",
    "plt.title(\"Wasserstein\")\n",
    "\n",
    "ax1 = plt.subplot(122, projection='3d')\n",
    "ax1.set_title(\"Wasserstein By Pose\")\n",
    "for i in range(10):\n",
    "    X = XWass[i*10:(i+1)*10, :]\n",
    "    ax1.scatter(X[:, 0], X[:, 1], X[:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Clustering of Nonrigid Shapes\n",
    "\n",
    "In this experiment, we will use a different sublevelset which is blind to <i>intrinsic isometries</i>.  This can be used to cluster shapes in a way which is invariant to articulated poses, which is complementary to the previous approach.  As our scalar function will use the \"heat kernel signature,\" which is a numerically stable way to compute curvature at multiple scales.  We will actually negate this signature, since we care more about local maxes than local mins in the scalar function.\n",
    "\n",
    "Let's explore a few examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "fn = lambda VPos, ITris: -getHKS(VPos, ITris, 20, t = 20)\n",
    "\n",
    "(VPos, _, ITris) = loadOffFile(\"new_McGill_benchmark/b%i.off\"%i)\n",
    "\n",
    "x = fn(VPos, ITris)\n",
    "I = do0DSublevelsetFiltrationMesh(VPos, ITris, fn)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(131)\n",
    "plotPCfn(VPos, x, cmap = 'afmhot')\n",
    "plt.title(\"Mesh %i\"%(subjectNum, poseNum))\n",
    "plt.subplot(132)\n",
    "plotPCfn(VPos[:, [2, 1, 0]], x, cmap = 'afmhot')\n",
    "plt.subplot(133)\n",
    "plot_dgms([I])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load in a few of the nonrigid meshes and compute the sublevelset function of their heat kernel signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "meshesNonrigid = []\n",
    "for i in range(N):\n",
    "    VPos, _, ITris = loadOffFile(\"new_McGill_benchmark/b%i.off\"%i)\n",
    "    meshesNonrigid.append((VPos, ITris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgmsNonrigid = []\n",
    "N = len(meshes)\n",
    "print(\"Computing persistence diagrams...\")\n",
    "for i, (VPos, ITris) in enumerate(meshes):\n",
    "    if i%10 == 0:\n",
    "        print(\"Finished first %i meshes\"%i)\n",
    "    x = fn(VPos, ITris)\n",
    "    I = do0DSublevelsetFiltrationMesh(VPos, ITris, lambda VPos, ITris: -getHKS(VPos, ITris, 20, t = 20))\n",
    "    I = I[np.isfinite(I[:, 1]), :]\n",
    "    dgmsNonrigid.append(I)\n",
    "\n",
    "# Compute Wasserstein distances\n",
    "DWassNonrigid = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(i+1, N):\n",
    "        _, DWassNonrigid[i, j], _ = getWassersteinDist(dgmsNonrigid[i], dgmsNonrigid[j])\n",
    "DWassNonrigid = DWassNonrigid + DWassNonrigid.T\n",
    "\n",
    "# Now do MDS and PCA, respectively\n",
    "mds = MDS(n_components=3, dissimilarity='precomputed')\n",
    "mds.fit_transform(DWassNonrigid)\n",
    "XWassNonrigid = mds.embedding_\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plt.imshow(DWassNonrigid, cmap = 'afmhot', interpolation = 'none')\n",
    "plt.title(\"Wasserstein\")\n",
    "\n",
    "ax1 = plt.subplot(122, projection='3d')\n",
    "ax1.set_title(\"Wasserstein By Pose\")\n",
    "ax1.scatter(XWassNonrigid [:, 0], XWassNonrigid [:, 1], XWassNonrigid [:, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
